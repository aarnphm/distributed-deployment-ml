{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4fd2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bentoml.transformers import TransformersModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508df9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = TransformersModel.load('distilbert-base-uncased', lm_head='masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = dc.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7136388",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"A Bento box is a [MASK] box that contains food.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31705e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(sentence,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86667ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = F.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ba4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = torch.where(inputs['input_ids'][0]==tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6930c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked, tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_word = softmax[0, masked, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849eb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = torch.topk(masked_word, 10, dim = 1)[1][0]\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e71c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in top_10:\n",
    "    word = tokenizer.decode([t])\n",
    "    new_sentence = sentence.replace(tokenizer.mask_token, word)\n",
    "    print(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ca4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c22aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aarnphm/.pyenv/versions/3.8.8/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorch.cache_wrapped import TransformersRunnable, GPTTransformers, create_transformers_runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dcfaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = TransformersRunnable('sentiment_analysis', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b173a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking setup while calling run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/gpt2/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/aarnphm/.cache/huggingface/transformers/tmpv4iiqi99\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae9aad57e844a32a96cda888a355d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/gpt2/resolve/main/config.json in cache at /home/aarnphm/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "creating metadata file for /home/aarnphm/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/aarnphm/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runnable.run(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c2b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
